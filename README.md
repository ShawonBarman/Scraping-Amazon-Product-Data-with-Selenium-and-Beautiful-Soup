# Scraping-Amazon-Product-Data-with-Selenium-and-Beautiful-Soup

<p>This code is divided into two parts, each responsible for a different aspect of scraping Amazon product data using Selenium and Beautiful Soup.</p>

<h3>Part 1 - Scraper:</h3>

<ul>
  <li>In this part, the code sets up Selenium to automate a headless Chrome browser and navigate to Amazon's website.</li>
  <li>It searches for products in a specific category (e.g., "tshirt for mens") and retrieves search results.</li>
  <li>The code scrapes product details such as title, category, sub-category, price, ratings, total ratings, and product URL from the search results.</li>
  <li>It checks if the data already exists in a CSV file and appends new data if it doesn't exist.</li>
  <li>The scraper then continues to the next page of search results and repeats the scraping process until there are no more pages of results.</li>
  <li>Finally, it closes the browser.</li>
</ul>

<h3>Part 2 - Data Refinement and Scraper:</h3>

<ul>
  <li>This part of the code reads the CSV file generated by the scraper in Part 1 using the Pandas library.</li>
  <li>It sets up Selenium once again to visit the product pages for each item listed in the CSV file.</li>
  <li>For each product, it extracts additional information such as product description and date first available.</li>
  <li>The code removes quotation marks from the title and appends all this data to a new CSV file, creating a more comprehensive dataset.</li>
  <li>After processing all products, it prints "All data saved done" and quits the Selenium WebDriver.</li>
</ul>

<p>Overall, these two parts work together to scrape product data from Amazon, refine it, and save it to a new CSV file for further analysis or use.</p>
